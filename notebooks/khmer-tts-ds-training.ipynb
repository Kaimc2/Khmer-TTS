{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Khmer Text-to-Speech Model training (Tecotron2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TTS Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA available: True\n",
      "CUDA version: 12.4\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "# Check backend version\n",
    "# print(f\"Audion backend: {torchaudio.get_audio_backend()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            line_index                                      transcription  \\\n",
      "0  khm_0308_0011865648  ស្ពាន កំពង់ ចម្លង អ្នកលឿង នៅ ព្រៃវែង ជា ស្ពាន ...   \n",
      "1  khm_0308_0032157149  ភ្លើង កំពុង ឆាប ឆេះ ផ្ទះ ប្រជា ពលរដ្ឋ នៅ សង្កា...   \n",
      "2  khm_0308_0038959268  អ្នក សុំ ទាន ដេក ប្រកាច់ ម្នាក់ ឯង ក្បែរ ខ្លោង...   \n",
      "3  khm_0308_0054635313  ស្ករ ត្នោត ដែល មាន គុណភាព ល្អ ផលិត នៅ ខេត្ត កំ...   \n",
      "4  khm_0308_0055735195         ភ្នំបាខែង មាន កម្ពស់ តែ ចិត សិប ម៉ែត្រ សោះ   \n",
      "\n",
      "                            normalized_transcription  \\\n",
      "0  ស្ពាន កំពង់ ចម្លង អ្នកលឿង នៅ ព្រៃវែង ជា ស្ពាន ...   \n",
      "1  ភ្លើង កំពុង ឆាប ឆេះ ផ្ទះ ប្រជា ពលរដ្ឋ នៅ សង្កា...   \n",
      "2  អ្នក សុំ ទាន ដេក ប្រកាច់ ម្នាក់ ឯង ក្បែរ ខ្លោង...   \n",
      "3  ស្ករ ត្នោត ដែល មាន គុណភាព ល្អ ផលិត នៅ ខេត្ត កំ...   \n",
      "4         ភ្នំបាខែង មាន កម្ពស់ តែ ចិត សិប ម៉ែត្រ សោះ   \n",
      "\n",
      "                                          mel_path  \\\n",
      "0  ../mel_spectrograms\\khm_0308_0011865648_mel.npy   \n",
      "1  ../mel_spectrograms\\khm_0308_0032157149_mel.npy   \n",
      "2  ../mel_spectrograms\\khm_0308_0038959268_mel.npy   \n",
      "3  ../mel_spectrograms\\khm_0308_0054635313_mel.npy   \n",
      "4  ../mel_spectrograms\\khm_0308_0055735195_mel.npy   \n",
      "\n",
      "                             tokenized_transcription  \n",
      "0  [0, 1, 2, 3, 4, 5, 6, 7, 2, 8, 9, 5, 10, 11, 1...  \n",
      "1  [26, 1, 12, 27, 8, 5, 6, 7, 2, 23, 8, 5, 28, 3...  \n",
      "2  [13, 1, 4, 6, 5, 0, 23, 7, 5, 31, 3, 4, 5, 32,...  \n",
      "3  [0, 1, 6, 16, 5, 34, 1, 4, 39, 34, 5, 32, 19, ...  \n",
      "4  [26, 1, 4, 7, 29, 3, 38, 19, 8, 5, 11, 3, 4, 5...  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset as dataframe\n",
    "processed_transcriptions = pd.read_csv('../dataset/processed_transcriptions.csv')\n",
    "\n",
    "print(processed_transcriptions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "train_data, val_data = train_test_split(processed_transcriptions, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['line_index', 'transcription', 'normalized_transcription', 'mel_path',\n",
      "       'tokenized_transcription'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "class TTSDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load the tokenized transcription\n",
    "        tokens = self.data.iloc[idx]['tokenized_transcription']\n",
    "        \n",
    "        # Convert tokens to tensor\n",
    "        if isinstance(tokens, str):\n",
    "            tokens = ast.literal_eval(tokens)\n",
    "        tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "        \n",
    "        # Load the mel spectrogram\n",
    "        mel_path = self.data.iloc[idx]['mel_path']\n",
    "        mel_spectrogram = np.load(mel_path)\n",
    "        mel_spectrogram = torch.tensor(mel_spectrogram, dtype=torch.float32)\n",
    "        \n",
    "        # Ensure mel spectrogram has shape [time, n_mels]\n",
    "        if mel_spectrogram.shape[1] != 80:  # Assuming 80 mel bins\n",
    "            mel_spectrogram = mel_spectrogram.transpose(0, 1)\n",
    "        \n",
    "        return tokens, mel_spectrogram\n",
    "\n",
    "def collate_fn(batch):\n",
    "    tokens, mel_spectrograms = zip(*batch)\n",
    "    \n",
    "    # Pad tokens\n",
    "    tokens = pad_sequence(tokens, batch_first=True, padding_value=0)\n",
    "    \n",
    "    # Get the maximum sequence length for mel spectrograms\n",
    "    max_length = max(mel.size(0) for mel in mel_spectrograms)\n",
    "    \n",
    "    # Pad mel spectrograms to have the same sequence length\n",
    "    padded_mels = []\n",
    "    for mel in mel_spectrograms:\n",
    "        # Calculate padding needed\n",
    "        pad_length = max_length - mel.size(0)\n",
    "        if pad_length > 0:\n",
    "            # Pad at the end (right side) of the sequence\n",
    "            padded_mel = torch.nn.functional.pad(mel, (0, 0, 0, pad_length))\n",
    "        else:\n",
    "            padded_mel = mel\n",
    "        padded_mels.append(padded_mel)\n",
    "    \n",
    "    # Stack the padded mel spectrograms and reshape to [batch, time, n_mels]\n",
    "    mel_spectrograms = torch.stack(padded_mels)\n",
    "    mel_spectrograms = mel_spectrograms.transpose(1, 2)  # Change to [batch, n_mels, time]\n",
    "    mel_spectrograms = mel_spectrograms.transpose(1, 2)  # Change to [batch, time, n_mels]\n",
    "    \n",
    "    return tokens, mel_spectrograms\n",
    "\n",
    "# Create the dataloaders\n",
    "train_dataset = TTSDataset(train_data)\n",
    "val_dataset = TTSDataset(val_data)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True, \n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True  # Drop incomplete batches\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=False, \n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True  # Drop incomplete batches\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tacotron2(nn.Module):\n",
    "    def __init__(self, n_vocab=256, embedding_dim=512, encoder_dim=512, decoder_dim=512, n_mels=80):\n",
    "        super(Tacotron2, self).__init__()\n",
    "        \n",
    "        # Text Embedding\n",
    "        self.embedding = nn.Embedding(n_vocab, embedding_dim)\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder_prenet = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, encoder_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(encoder_dim, encoder_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.encoder_lstm = nn.LSTM(\n",
    "            input_size=encoder_dim,\n",
    "            hidden_size=encoder_dim // 2,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder_prenet = nn.Sequential(\n",
    "            nn.Linear(n_mels, decoder_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(decoder_dim, decoder_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.decoder_lstm = nn.LSTM(\n",
    "            input_size=decoder_dim + encoder_dim,\n",
    "            hidden_size=decoder_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Output projection\n",
    "        self.mel_projection = nn.Linear(decoder_dim, n_mels)\n",
    "        \n",
    "        # Postnet\n",
    "        self.postnet = nn.Sequential(\n",
    "            nn.Conv1d(n_mels, 512, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv1d(512, 512, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv1d(512, n_mels, kernel_size=5, padding=2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, text, mel_target=None):\n",
    "        # Text embedding\n",
    "        embedded = self.embedding(text)  # [batch, text_length, embedding_dim]\n",
    "        \n",
    "        # Encoder\n",
    "        encoder_input = self.encoder_prenet(embedded)\n",
    "        encoder_output, _ = self.encoder_lstm(encoder_input)  # [batch, text_length, encoder_dim]\n",
    "        \n",
    "        batch_size = text.size(0)\n",
    "        \n",
    "        # Initialize decoder input (moved outside the conditional)\n",
    "        go_frame = torch.zeros(batch_size, 1, self.mel_projection.out_features).to(text.device)\n",
    "        \n",
    "        if self.training and mel_target is not None:\n",
    "            # Teacher forcing: concatenate go_frame with target mel frames\n",
    "            decoder_inputs = torch.cat((go_frame, mel_target[:, :-1, :]), dim=1)\n",
    "            \n",
    "            # Process through decoder prenet\n",
    "            decoder_inputs = self.decoder_prenet(decoder_inputs)  # [batch, mel_length, decoder_dim]\n",
    "            \n",
    "            # Prepare encoder outputs for attention\n",
    "            # Expand encoder outputs to match decoder sequence length\n",
    "            expanded_encoder_output = encoder_output.unsqueeze(1)  # [batch, 1, text_length, encoder_dim]\n",
    "            expanded_encoder_output = expanded_encoder_output.expand(\n",
    "                -1, decoder_inputs.size(1), -1, -1)  # [batch, mel_length, text_length, encoder_dim]\n",
    "            \n",
    "            # For now, use simple averaging of encoder outputs\n",
    "            context_vectors = expanded_encoder_output.mean(dim=2)  # [batch, mel_length, encoder_dim]\n",
    "            \n",
    "            # Concatenate decoder inputs with context vectors\n",
    "            decoder_lstm_input = torch.cat((decoder_inputs, context_vectors), dim=-1)\n",
    "            \n",
    "            # Decoder LSTM\n",
    "            decoder_output, _ = self.decoder_lstm(decoder_lstm_input)\n",
    "            \n",
    "            # Project to mel-spectrogram\n",
    "            mel_output = self.mel_projection(decoder_output)\n",
    "            \n",
    "            # Postnet processing\n",
    "            mel_output_postnet = self.postnet(mel_output.transpose(1, 2)).transpose(1, 2)\n",
    "            mel_output_refined = mel_output + mel_output_postnet\n",
    "            \n",
    "            return mel_output, mel_output_refined\n",
    "        else:\n",
    "            # Determine output length\n",
    "            if mel_target is not None:\n",
    "                # For validation: use target length\n",
    "                target_length = mel_target.size(1)\n",
    "            else:\n",
    "                # For inference: use maximum length\n",
    "                target_length = 1000\n",
    "                \n",
    "            mel_outputs = []\n",
    "            current_frame = go_frame\n",
    "            \n",
    "            for _ in range(target_length):\n",
    "                # Process current frame through prenet\n",
    "                prenet_out = self.decoder_prenet(current_frame)\n",
    "                \n",
    "                # Get context vector (simplified attention)\n",
    "                context_vector = encoder_output.mean(dim=1, keepdim=True)\n",
    "                \n",
    "                # Concatenate and process through LSTM\n",
    "                decoder_input = torch.cat((prenet_out, context_vector.expand(-1, 1, -1)), dim=-1)\n",
    "                decoder_output, _ = self.decoder_lstm(decoder_input)\n",
    "                \n",
    "                # Generate next frame\n",
    "                current_frame = self.mel_projection(decoder_output)\n",
    "                mel_outputs.append(current_frame)\n",
    "                \n",
    "                # Stop if we predict a stop token (you'll need to implement this)\n",
    "                \n",
    "            mel_outputs = torch.cat(mel_outputs, dim=1)\n",
    "            mel_outputs_postnet = self.postnet(mel_outputs.transpose(1, 2)).transpose(1, 2)\n",
    "            mel_outputs_refined = mel_outputs + mel_outputs_postnet\n",
    "            \n",
    "            return mel_outputs, mel_outputs_refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    for tokens, mel_spectrograms in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        try:\n",
    "            tokens = tokens.to(device)\n",
    "            mel_spectrograms = mel_spectrograms.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            mel_output, mel_output_refined = model(tokens, mel_spectrograms)\n",
    "            \n",
    "            # Compute loss (combining both outputs)\n",
    "            loss = criterion(mel_output, mel_spectrograms) + criterion(mel_output_refined, mel_spectrograms)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Add gradient clipping\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            batch_count += 1\n",
    "            \n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error in batch: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return epoch_loss / batch_count if batch_count > 0 else float('inf')\n",
    "\n",
    "# Modified validation function with error handling\n",
    "def validate_one_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for tokens, mel_spectrograms in tqdm(loader, desc=\"Validation\", leave=False):\n",
    "            try:\n",
    "                tokens = tokens.to(device)\n",
    "                mel_spectrograms = mel_spectrograms.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                mel_output, mel_output_refined = model(tokens, mel_spectrograms)\n",
    "                \n",
    "                # Compute loss\n",
    "                loss = criterion(mel_output, mel_spectrograms) + criterion(mel_output_refined, mel_spectrograms)\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "                batch_count += 1\n",
    "                \n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error in validation batch: {e}\")\n",
    "                continue\n",
    "    \n",
    "    return epoch_loss / batch_count if batch_count > 0 else float('inf')\n",
    "\n",
    "# Initialize model and move to device\n",
    "model = Tacotron2(\n",
    "    n_vocab=256,\n",
    "    embedding_dim=512,\n",
    "    encoder_dim=512,\n",
    "    decoder_dim=512,\n",
    "    n_mels=80\n",
    ").to(device)\n",
    "\n",
    "# Initialize optimizer and criterion\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1574.8424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6020.9544\n",
      "Saved best model!\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 983.3863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5055.8333\n",
      "Saved best model!\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 934.9413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2319.3285\n",
      "Saved best model!\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 890.3351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1834.5391\n",
      "Saved best model!\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 827.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2094.4998\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 745.3214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3061.4314\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 657.5508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3397.1665\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 544.4181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3288.4491\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 431.5051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2657.4871\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 310.2101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3156.0175\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 205.6654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3406.4183\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 171.2692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3576.1490\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 164.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3634.3490\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 154.7960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3714.4941\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 145.2554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3710.2556\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 139.0830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3900.7633\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 136.8008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3965.8009\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 134.8769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4075.8133\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 128.4979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4107.8998\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 126.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4288.8414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 20\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # Validate\n",
    "    val_loss = validate_one_epoch(model, val_loader, criterion, device)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Save the best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_tacotron2_model.pth\")\n",
    "        print(\"Saved best model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Khmer Text-to-Speech Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchaudio\n",
    "# import numpy as np\n",
    "# import librosa\n",
    "# from IPython.display import Audio\n",
    "# import pandas as pd\n",
    "\n",
    "# def create_char_to_id_mapping(processed_transcriptions, max_vocab_size=256):\n",
    "#     \"\"\"Create character to ID mapping with vocabulary size limit\"\"\"\n",
    "#     # Create a set of all unique characters\n",
    "#     unique_chars = set()\n",
    "#     for text in processed_transcriptions['normalized_transcription']:\n",
    "#         chars = text.strip().split()\n",
    "#         unique_chars.update(chars)\n",
    "    \n",
    "#     # Sort characters to ensure consistent ordering\n",
    "#     sorted_chars = sorted(list(unique_chars))\n",
    "    \n",
    "#     # Limit vocabulary size if necessary\n",
    "#     if len(sorted_chars) + 2 > max_vocab_size:  # +2 for <pad> and <unk>\n",
    "#         print(f\"Warning: Truncating vocabulary from {len(sorted_chars)} to {max_vocab_size-2}\")\n",
    "#         sorted_chars = sorted_chars[:max_vocab_size-2]\n",
    "    \n",
    "#     # Create mapping dictionary\n",
    "#     char_to_id = {char: idx for idx, char in enumerate(sorted_chars)}\n",
    "    \n",
    "#     # Add special tokens\n",
    "#     char_to_id['<pad>'] = len(char_to_id)\n",
    "#     char_to_id['<unk>'] = len(char_to_id)\n",
    "    \n",
    "#     print(f\"Total vocabulary size: {len(char_to_id)}\")\n",
    "#     return char_to_id\n",
    "\n",
    "# def text_to_sequence(text, char_to_id):\n",
    "#     \"\"\"Convert Khmer text to sequence of token IDs\"\"\"\n",
    "#     chars = text.strip().split()\n",
    "#     return [char_to_id.get(char, char_to_id['<unk>']) for char in chars]\n",
    "\n",
    "# def generate_mel_spectrogram(model, text_sequence, device):\n",
    "#     \"\"\"Generate mel spectrogram with error handling\"\"\"\n",
    "#     try:\n",
    "#         with torch.no_grad():\n",
    "#             text_tensor = torch.LongTensor([text_sequence]).to(device)\n",
    "#             print(f\"Input tensor shape: {text_tensor.shape}\")\n",
    "#             mel_output, mel_output_refined = model(text_tensor)\n",
    "#             return mel_output_refined.cpu().numpy()[0]\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in generate_mel_spectrogram: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def generate_audio_librosa(mel_spectrogram):\n",
    "#     \"\"\"Generate audio using librosa\"\"\"\n",
    "#     try:\n",
    "#         # Create mel filterbank\n",
    "#         mel_basis = librosa.filters.mel(\n",
    "#             sr=22050,\n",
    "#             n_fft=1024,\n",
    "#             n_mels=80,\n",
    "#             fmin=0,\n",
    "#             fmax=8000,\n",
    "#         )\n",
    "        \n",
    "#         # Print shapes for debugging\n",
    "#         print(f\"Mel spectrogram shape: {mel_spectrogram.shape}\")\n",
    "#         print(f\"Mel basis shape: {mel_basis.shape}\")\n",
    "        \n",
    "#         # Compute pseudoinverse of mel filterbank\n",
    "#         mel_inverse = np.linalg.pinv(mel_basis)\n",
    "        \n",
    "#         # Convert mel spectrogram to linear spectrogram\n",
    "#         linear_spectrogram = np.dot(mel_inverse, mel_spectrogram.T).T\n",
    "        \n",
    "#         # Ensure non-negative values\n",
    "#         linear_spectrogram = np.maximum(1e-10, linear_spectrogram)\n",
    "        \n",
    "#         # Use librosa's istft\n",
    "#         audio = librosa.istft(\n",
    "#             linear_spectrogram.astype(np.complex64),\n",
    "#             hop_length=256,\n",
    "#             win_length=1024\n",
    "#         )\n",
    "        \n",
    "#         return audio\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in librosa audio generation: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def generate_audio_torchaudio(mel_spectrogram):\n",
    "#     \"\"\"Generate audio using torchaudio\"\"\"\n",
    "#     try:\n",
    "#         mel_tensor = torch.FloatTensor(mel_spectrogram)\n",
    "#         griffin_lim = torchaudio.transforms.GriffinLim(\n",
    "#             n_fft=1024,\n",
    "#             n_iter=32,\n",
    "#             win_length=1024,\n",
    "#             hop_length=256\n",
    "#         )\n",
    "#         waveform = griffin_lim(mel_tensor)\n",
    "#         return waveform.numpy()\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in torchaudio audio generation: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def run_demo(force_cpu=False, use_torch_version=False):\n",
    "#     \"\"\"Run the complete demo pipeline\"\"\"\n",
    "#     try:\n",
    "#         # 1. Setup device\n",
    "#         device = torch.device('cpu') if force_cpu else torch.device('cuda')\n",
    "#         print(f\"Using device: {device}\")\n",
    "        \n",
    "#         # 2. Load processed transcriptions\n",
    "#         processed_transcriptions = pd.read_csv('../dataset/processed_transcriptions.csv')\n",
    "        \n",
    "#         # 3. Load model state dict\n",
    "#         state_dict = torch.load(\"best_tacotron2_model.pth\", \n",
    "#                               map_location='cpu' if force_cpu else device)\n",
    "        \n",
    "#         saved_vocab_size = state_dict['embedding.weight'].shape[0]\n",
    "#         print(f\"Saved model vocabulary size: {saved_vocab_size}\")\n",
    "        \n",
    "#         # 4. Initialize model\n",
    "#         model = Tacotron2(\n",
    "#             n_vocab=saved_vocab_size,\n",
    "#             embedding_dim=512,\n",
    "#             encoder_dim=512,\n",
    "#             decoder_dim=512,\n",
    "#             n_mels=80\n",
    "#         )\n",
    "        \n",
    "#         # 5. Load weights\n",
    "#         model.load_state_dict(state_dict)\n",
    "#         model = model.to(device)\n",
    "#         model.eval()\n",
    "        \n",
    "#         # 6. Create character mapping\n",
    "#         char_to_id = create_char_to_id_mapping(processed_transcriptions, max_vocab_size=saved_vocab_size)\n",
    "        \n",
    "#         # 7. Prepare test text\n",
    "#         test_text = \"សួស្តី\"  # \"Hello\"\n",
    "#         print(f\"\\nProcessing text: {test_text}\")\n",
    "        \n",
    "#         # 8. Convert text to sequence\n",
    "#         text_sequence = text_to_sequence(test_text, char_to_id)\n",
    "#         print(f\"Token sequence: {text_sequence}\")\n",
    "        \n",
    "#         # 9. Generate mel spectrogram\n",
    "#         print(\"\\nGenerating mel spectrogram...\")\n",
    "#         mel_spectrogram = generate_mel_spectrogram(model, text_sequence, device)\n",
    "        \n",
    "#         # 10. Convert to audio using selected method\n",
    "#         print(\"Converting to audio...\")\n",
    "#         if use_torch_version:\n",
    "#             audio = generate_audio_torchaudio(mel_spectrogram)\n",
    "#         else:\n",
    "#             audio = generate_audio_librosa(mel_spectrogram)\n",
    "        \n",
    "#         # 11. Normalize audio\n",
    "#         audio = audio / np.max(np.abs(audio))\n",
    "        \n",
    "#         return Audio(audio, rate=22050)\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"\\nError in demo: {e}\")\n",
    "#         if torch.cuda.is_available():\n",
    "#             print(f\"CUDA Memory allocated: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
    "#             print(f\"CUDA Memory cached: {torch.cuda.memory_reserved()/1024**2:.2f} MB\")\n",
    "#         raise\n",
    "\n",
    "# # Try running with both implementations\n",
    "# print(\"Testing with librosa implementation...\")\n",
    "# try:\n",
    "#     audio_player = run_demo(force_cpu=True, use_torch_version=False)\n",
    "#     print(\"\\nLibrosa implementation successful!\")\n",
    "#     display(audio_player)\n",
    "# except Exception as e:\n",
    "#     print(f\"\\nLibrosa implementation failed: {e}\")\n",
    "#     print(\"\\nTrying torchaudio implementation...\")\n",
    "#     try:\n",
    "#         audio_player = run_demo(force_cpu=True, use_torch_version=True)\n",
    "#         print(\"\\nTorchaudio implementation successful!\")\n",
    "#         display(audio_player)\n",
    "#     except Exception as e:\n",
    "#         print(f\"\\nBoth implementations failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
