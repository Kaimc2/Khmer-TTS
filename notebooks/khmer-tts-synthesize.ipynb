{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Code Files\\Python\\Data Science\\Khmer-TTS\\WaveRNN\\models\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from unidecode import unidecode\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from IPython.display import Audio\n",
    "\n",
    "print(os.path.abspath(os.path.join('..', 'WaveRNN/models')))\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'WaveRNN')))\n",
    "\n",
    "from models.fatchord_version import WaveRNN\n",
    "from models.tacotron import Tacotron\n",
    "from utils.text.symbols import symbols\n",
    "from utils.text import text_to_sequence\n",
    "from utils import hparams as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Initialising WaveRNN Model...\n",
      "\n",
      "Trainable Parameters: 4.234M\n",
      "\n",
      "Initialising Tacotron Model...\n",
      "\n",
      "Trainable Parameters: 11.088M\n"
     ]
    }
   ],
   "source": [
    "if not hp.is_configured():\n",
    "    hp.configure(os.path.abspath(os.path.join('..', 'WaveRNN/hparams.py')))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "print('\\nInitialising WaveRNN Model...\\n')\n",
    "\n",
    "vocoder = WaveRNN(rnn_dims=hp.voc_rnn_dims,\n",
    "                    fc_dims=hp.voc_fc_dims,\n",
    "                    bits=hp.bits,\n",
    "                    pad=hp.voc_pad,\n",
    "                    upsample_factors=hp.voc_upsample_factors,\n",
    "                    feat_dims=hp.num_mels,\n",
    "                    compute_dims=hp.voc_compute_dims,\n",
    "                    res_out_dims=hp.voc_res_out_dims,\n",
    "                    res_blocks=hp.voc_res_blocks,\n",
    "                    hop_length=hp.hop_length,\n",
    "                    sample_rate=hp.sample_rate,\n",
    "                    mode=hp.voc_mode\n",
    "                ).to(device)\n",
    "\n",
    "# vocoder.load(os.path.abspath(os.path.join('..', 'WaveRNN/checkpoints/ljspeech_mol.wavernn/latest_weights.pyt')))\n",
    "vocoder.load(os.path.abspath(os.path.join('..', 'WaveRNN/checkpoints/ljspeech_mol.wavernn/wave_step200k_weights.pyt')))\n",
    "\n",
    "print('\\nInitialising Tacotron Model...\\n')\n",
    "\n",
    "# Instantiate Tacotron Model\n",
    "tts_model = Tacotron(embed_dims=hp.tts_embed_dims,\n",
    "                        num_chars=len(symbols),\n",
    "                        encoder_dims=hp.tts_encoder_dims,\n",
    "                        decoder_dims=hp.tts_decoder_dims,\n",
    "                        n_mels=hp.num_mels,\n",
    "                        fft_bins=hp.num_mels,\n",
    "                        postnet_dims=hp.tts_postnet_dims,\n",
    "                        encoder_K=hp.tts_encoder_K,\n",
    "                        lstm_dims=hp.tts_lstm_dims,\n",
    "                        postnet_K=hp.tts_postnet_K,\n",
    "                        num_highways=hp.tts_num_highways,\n",
    "                        dropout=hp.tts_dropout,\n",
    "                        stop_threshold=hp.tts_stop_threshold).to(device)\n",
    "\n",
    "tts_model.load(os.path.abspath(os.path.join('..', 'WaveRNN/checkpoints/ljspeech_lsa_smooth_attention.tacotron/latest_weights.pyt')))\n",
    "# tts_model.load(os.path.abspath(os.path.join('..', 'WaveRNN/checkpoints/ljspeech_lsa_smooth_attention.tacotron/taco_step20k_weights.pyt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_text(input_text):\n",
    "    encoded_text = unidecode(input_text)\n",
    "\n",
    "    inputs = [text_to_sequence(encoded_text.strip(), hp.tts_cleaner_names)]\n",
    "    print(inputs)\n",
    "    \n",
    "    for i, x in enumerate(inputs, 1):\n",
    "\n",
    "        print(f'\\n| Generating {i}/{len(inputs)}')\n",
    "        _, m, attention = tts_model.generate(x)\n",
    "        # Fix mel spectrogram scaling to be from 0 to 1\n",
    "        m = (m + 4) / 8\n",
    "        np.clip(m, 0, 1, out=m)\n",
    "\n",
    "        m = torch.tensor(m).unsqueeze(0)\n",
    "\n",
    "        # Generate audio from mel spectrogram using WaveRNN\n",
    "        output = vocoder.generate(m, hp.voc_gen_batched, hp.voc_target, hp.voc_overlap, hp.mu_law)\n",
    "\n",
    "        return Audio(output.astype(np.float32), rate=hp.sample_rate)\n",
    "\n",
    "    print('\\n\\nDone.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39, 55, 45, 11, 55, 38, 38, 47, 38, 38, 51, 51, 38, 38, 40, 48, 55, 11, 48, 50, 39, 58, 47, 38, 38]]\n",
      "\n",
      "| Generating 1/1\n",
      "| ████████████████ 72000/72600 | Batch Size: 6 | Gen Rate: 2.9kHz | "
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "No format specified and unable to get format from file extension: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mព្រះ រាជាណាចក្រ កម្ពុជា\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m synthesize_text(input_text)\n",
      "Cell \u001b[1;32mIn[27], line 18\u001b[0m, in \u001b[0;36msynthesize_text\u001b[1;34m(input_text)\u001b[0m\n\u001b[0;32m     15\u001b[0m     m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Generate audio from mel spectrogram using WaveRNN\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     output \u001b[38;5;241m=\u001b[39m vocoder\u001b[38;5;241m.\u001b[39mgenerate(m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, hp\u001b[38;5;241m.\u001b[39mvoc_gen_batched, hp\u001b[38;5;241m.\u001b[39mvoc_target, hp\u001b[38;5;241m.\u001b[39mvoc_overlap, hp\u001b[38;5;241m.\u001b[39mmu_law)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Audio(output\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32), rate\u001b[38;5;241m=\u001b[39mhp\u001b[38;5;241m.\u001b[39msample_rate)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDone.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Code Files\\Python\\Data Science\\Khmer-TTS\\WaveRNN\\models\\fatchord_version.py:355\u001b[0m, in \u001b[0;36mgenerate\u001b[1;34m(self, mels, save_path, batched, target, overlap, mu_law)\u001b[0m\n\u001b[0;32m    352\u001b[0m output \u001b[38;5;241m=\u001b[39m output[:wave_len]\n\u001b[0;32m    353\u001b[0m output[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m20\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhop_length:] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m fade_out\n\u001b[1;32m--> 355\u001b[0m save_wav(output, save_path)\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32md:\\Code Files\\Python\\Data Science\\Khmer-TTS\\WaveRNN\\utils\\dsp.py:24\u001b[0m, in \u001b[0;36msave_wav\u001b[1;34m(x, path)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_wav\u001b[39m(x, path):\n\u001b[1;32m---> 24\u001b[0m     sf\u001b[38;5;241m.\u001b[39mwrite(path, x\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32), hp\u001b[38;5;241m.\u001b[39msample_rate)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\my-env\\Lib\\site-packages\\soundfile.py:343\u001b[0m, in \u001b[0;36mwrite\u001b[1;34m(file, data, samplerate, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    342\u001b[0m     channels \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 343\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SoundFile(file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, samplerate, channels,\n\u001b[0;32m    344\u001b[0m                subtype, endian, \u001b[38;5;28mformat\u001b[39m, closefd) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    345\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\my-env\\Lib\\site-packages\\soundfile.py:656\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    654\u001b[0m mode_int \u001b[38;5;241m=\u001b[39m _check_mode(mode)\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m--> 656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(file, mode_int, closefd)\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\my-env\\Lib\\site-packages\\soundfile.py:1466\u001b[0m, in \u001b[0;36m_create_info_struct\u001b[1;34m(file, mode, samplerate, channels, format, subtype, endian)\u001b[0m\n\u001b[0;32m   1464\u001b[0m original_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m\n\u001b[0;32m   1465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1466\u001b[0m     \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m _get_format_from_filename(file, mode)\n\u001b[0;32m   1467\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mformat\u001b[39m, (_unicode, \u001b[38;5;28mstr\u001b[39m))\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\miniconda3\\envs\\my-env\\Lib\\site-packages\\soundfile.py:1507\u001b[0m, in \u001b[0;36m_get_format_from_filename\u001b[1;34m(file, mode)\u001b[0m\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _formats \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m-> 1507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo format specified and unable to get format from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1508\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile extension: \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(file))\n\u001b[0;32m   1509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: No format specified and unable to get format from file extension: ''"
     ]
    }
   ],
   "source": [
    "input_text = \"ព្រះ រាជាណាចក្រ កម្ពុជា\"\n",
    "synthesize_text(input_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
