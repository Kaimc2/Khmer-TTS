{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Khmer Text-to-Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2906, 2)\n",
      "            line_index                                      transcription\n",
      "0  khm_0308_0011865648  ស្ពាន កំពង់ ចម្លង អ្នកលឿង នៅ ព្រៃវែង ជា ស្ពាន ...\n",
      "1  khm_0308_0032157149  ភ្លើង កំពុង ឆាប ឆេះ ផ្ទះ ប្រជា ពលរដ្ឋ នៅ សង្កា...\n",
      "2  khm_0308_0038959268  អ្នក សុំ ទាន ដេក ប្រកាច់ ម្នាក់ ឯង ក្បែរ ខ្លោង...\n",
      "3  khm_0308_0054635313  ស្ករ ត្នោត ដែល មាន គុណភាព ល្អ ផលិត នៅ ខេត្ត កំ...\n",
      "4  khm_0308_0055735195         ភ្នំបាខែង មាន កម្ពស់ តែ ចិត សិប ម៉ែត្រ សោះ\n"
     ]
    }
   ],
   "source": [
    "transcriptions_path = '../dataset/line_index.tsv'\n",
    "transcriptions = pd.read_csv(transcriptions_path, sep='\\t\\t', names=['line_index', 'transcription'], engine='python')\n",
    "\n",
    "# Dataset overview\n",
    "print(transcriptions.shape)\n",
    "print(transcriptions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration: 3.9667806481481387 hours\n",
      "Total text length: 146460 characters\n"
     ]
    }
   ],
   "source": [
    "total_duration = 0\n",
    "total_text_length = 0\n",
    "\n",
    "dataset_path = '../dataset'\n",
    "\n",
    "# Calculate audio duration and text length\n",
    "for line_index, transcription in zip(transcriptions['line_index'], transcriptions['transcription']):\n",
    "    # print(f'Processing {line_index}')\n",
    "    wav_path = os.path.join(dataset_path, 'wavs', f'{line_index}.wav')\n",
    "    \n",
    "    if os.path.exists(wav_path):\n",
    "        y, sr = librosa.load(wav_path, sr=None)\n",
    "        duration = librosa.get_duration(y=y, sr=sr)\n",
    "        total_duration += duration\n",
    "        total_text_length += len(transcription)\n",
    "    else:\n",
    "        print(f'File not found: {wav_path}')\n",
    "\n",
    "# Print Statistics\n",
    "total_duration_hours = total_duration / 3600\n",
    "print(f'Total duration: {total_duration_hours} hours')\n",
    "print(f'Total text length: {total_text_length} characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_lengths = []\n",
    "text_lengths = []\n",
    "\n",
    "for line_index, transcription in zip(transcriptions['line_index'], transcriptions['transcription']): \n",
    "    wav_path = os.path.join(dataset_path, 'wavs', f'{line_index}.wav')\n",
    "    y, sr = librosa.load(wav_path, sr=None)\n",
    "    audio_lengths.append(librosa.get_duration(y=y, sr=sr))\n",
    "    text_lengths.append(len(transcription))\n",
    "\n",
    "# # Plot historgram\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.hist(audio_lengths, bins=30, color='blue', edgecolor='black', align= 'mid')\n",
    "# plt.title('Audio Length Distribution')\n",
    "# plt.xlabel('Duration (seconds)')\n",
    "# plt.ylabel('Count')\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.hist(text_lengths, bins=30, color='blue', edgecolor='black', align= 'mid')\n",
    "# plt.title('Text Length Distribution')\n",
    "# plt.xlabel('Length (characters)')\n",
    "# plt.ylabel('Frequency')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize a random audio file\n",
    "# random_file = os.path.join(dataset_path, 'wavs', transcriptions.sample(1)['line_index'].values[0] + '.wav')\n",
    "# y, sr = librosa.load(random_file, sr=None)\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# plt.plot(y)\n",
    "# plt.title('Waveform of a random audio file')\n",
    "# plt.xlabel('Samples')\n",
    "# plt.ylabel('Amplitude')\n",
    "# plt.show()\n",
    "\n",
    "# # Listen to the audio file if running locally\n",
    "# import IPython.display as ipd\n",
    "# ipd.Audio(random_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Identify and handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers\n",
    "short_audio = transcriptions[[length < 1 for length in audio_lengths]] # Audio files less than 1 second\n",
    "long_audio = transcriptions[[length > 10 for length in audio_lengths]] # Audio files more than 10 seconds\n",
    "\n",
    "# print(f\"Short audio files: {short_audio}\") # All Dataset audio are longer than 1 second\n",
    "# print(f\"Long audio files: {long_audio}\") \n",
    "\n",
    "# Overview\n",
    "# - We found 17 audio files that are longer than 10 seconds which considered as outliers\n",
    "# - Fortunately, there are no audio which are shorter than 1 second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples after removing outliers: 2889\n"
     ]
    }
   ],
   "source": [
    "# Removing Outliers\n",
    "for line_index in long_audio['line_index']:\n",
    "    wav_path = os.path.join(dataset_path, 'wavs', f'{line_index}.wav')\n",
    "    os.remove(wav_path)\n",
    "\n",
    "# Remove outliers from the dataset\n",
    "transcriptions = transcriptions[~transcriptions['line_index'].isin(long_audio['line_index'])]\n",
    "\n",
    "# Check dataset size\n",
    "print(f'Number of samples after removing outliers: {len(transcriptions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^ក-៹ ]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "transcriptions['normalized_transcription'] = transcriptions['transcription'].apply(normalize_text)\n",
    "\n",
    "# Save the normalized transcriptions\n",
    "# transcriptions.to_csv(\"dataset/processed_transcriptions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Audio Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(audio_path, target_sample_rate=16000):\n",
    "    audio, sr = librosa.load(audio_path, sr=None)\n",
    "    # Resample \n",
    "    if sr != target_sample_rate:\n",
    "        audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sample_rate)\n",
    "    \n",
    "    # Normalize\n",
    "    audio = librosa.util.normalize(audio)\n",
    "\n",
    "    # Trim silence\n",
    "    audio, _ = librosa.effects.trim(audio)\n",
    "\n",
    "    return audio, target_sample_rate\n",
    "\n",
    "# Apply preprocessing to audio files\n",
    "for line_index in transcriptions['line_index']:\n",
    "    audio_path = os.path.join(dataset_path, 'wavs', f'{line_index}.wav')\n",
    "    audio, sr = preprocess_audio(audio_path)\n",
    "    sf.write(audio_path, audio, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mel_spectogram(audio, sr, n_mels=80, n_fft=2048, hop_length=512):\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=audio,\n",
    "        sr=sr,\n",
    "        n_mels=n_mels,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length\n",
    "    )\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    return mel_spec_db\n",
    "\n",
    "mel_spec = extract_mel_spectogram(audio, sr)\n",
    "\n",
    "# Visualize Spectogram\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# librosa.display.specshow(mel_spec, sr=sr, hop_length=512, x_axis='time', y_axis='mel')\n",
    "# plt.colorbar(format='%+2.0f dB')\n",
    "# plt.title('Mel Spectrogram')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2889/2889 [00:13<00:00, 213.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extract Mel Spectrogram for all audio files\n",
    "output_dir = \"../mel_spectrograms\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process and save mel spectrograms for all audio files\n",
    "for idx, row in tqdm(transcriptions.iterrows(), total=len(transcriptions)):\n",
    "    audio_path = os.path.join(dataset_path, 'wavs', f'{row[\"line_index\"]}.wav')\n",
    "\n",
    "    try:\n",
    "        # Load audio file\n",
    "        audio, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "        # Extract Mel Spectrogram\n",
    "        mel_spec = extract_mel_spectogram(audio, sr)\n",
    "\n",
    "        # Save the mel spectrogram as .npy file\n",
    "        mel_path = mel_path = os.path.join(output_dir, f\"{row['line_index']}_mel.npy\")\n",
    "        np.save(mel_path, mel_spec)\n",
    "\n",
    "        # Update dataset with mel spectrogram path\n",
    "        transcriptions.loc[idx, 'mel_path'] = mel_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Tokenize Transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary from the dataset\n",
    "from collections import Counter\n",
    "\n",
    "vocab = Counter(''.join(transcriptions['normalized_transcription']))\n",
    "char_to_index = {char: idx for idx, char in enumerate(vocab.keys())}\n",
    "\n",
    "# Tokenize transcriptions\n",
    "def tokenize_text(text, char_to_index):\n",
    "    return [char_to_index[char] for char in text if char in char_to_index]\n",
    "\n",
    "transcriptions['tokenized_transcription'] = transcriptions['normalized_transcription'].apply(lambda x: tokenize_text(x, char_to_index))\n",
    "\n",
    "# print(transcriptions.head())\n",
    "\n",
    "# Create assets directory if it doesn't exist\n",
    "os.makedirs(\"../assets\", exist_ok=True)\n",
    "\n",
    "# Save the char_to_index mapping\n",
    "with open(\"../assets/char_to_index.pkl\", \"wb\") as f:\n",
    "    pickle.dump(char_to_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the tokenized transcriptions\n",
    "transcriptions.to_csv(\"../dataset/processed_transcriptions.csv\", index=False)\n",
    "\n",
    "# # Save the spectograms\n",
    "# with open(\"../assets/mel_spectrograms.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(mel_spec, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out the training notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "khmer-tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
